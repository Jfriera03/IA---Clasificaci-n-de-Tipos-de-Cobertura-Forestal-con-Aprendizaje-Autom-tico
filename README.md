# ğŸ” ClasificaciÃ³n de Tipos de Cobertura Forestal

## ğŸ¤ Colaboradores

- [Jfriera03](https://github.com/Jfriera03)
- [MasoalM](https://github.com/MasoalM)

## ğŸ“Œ DescripciÃ³n

Este proyecto implementa **modelos de aprendizaje automÃ¡tico** para la clasificaciÃ³n de tipos de cobertura forestal. Se utilizan diversas tÃ©cnicas de clasificaciÃ³n supervisada para analizar y predecir la vegetaciÃ³n en funciÃ³n de caracterÃ­sticas geogrÃ¡ficas y ambientales.

## ğŸ› ï¸ TecnologÃ­as y Herramientas

- **Lenguaje:** Python ğŸ
- **LibrerÃ­as utilizadas:** `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`.
- **Estructuras de datos empleadas:**
  - DataFrames de `pandas` para manipulaciÃ³n de datos.
  - Arrays de `numpy` para cÃ¡lculos numÃ©ricos.
  - Modelos de `scikit-learn` para clasificaciÃ³n.

## ğŸ“Œ Arquitectura del CÃ³digo

El cÃ³digo estÃ¡ estructurado en un **Notebook Jupyter** (`.ipynb`), en el que se incluyen:

1. **Carga y exploraciÃ³n de datos:** AnÃ¡lisis exploratorio del conjunto **Forest Cover Type Dataset**.
2. **Preprocesamiento de datos:** Limpieza, transformaciÃ³n y selecciÃ³n de caracterÃ­sticas.
3. **Entrenamiento de modelos:** ComparaciÃ³n entre varios algoritmos de clasificaciÃ³n.
4. **EvaluaciÃ³n de modelos:** AnÃ¡lisis de mÃ©tricas y visualizaciÃ³n de resultados.
5. **DiscusiÃ³n de resultados:** ComparaciÃ³n crÃ­tica de los modelos y su rendimiento.

## ğŸš€ InstalaciÃ³n y Uso

1. Clona el repositorio:
   ```bash
   git clone https://github.com/Jfriera03/clasificacion-cobertura-forestal.git
   ```
2. Accede al directorio del proyecto:
   ```bash
   cd clasificacion-cobertura-forestal
   ```
3. Instala las dependencias necesarias:
   ```bash
   pip install -r requirements.txt
   ```
4. Abre el Notebook Jupyter:
   ```bash
   jupyter notebook PrÃ¡ctica3.ipynb
   ```

## ğŸ® Modelos Implementados

Los siguientes modelos de clasificaciÃ³n han sido implementados y comparados:

### ğŸ”¹ PerceptrÃ³n
- Algoritmo basado en redes neuronales simples.
- Sensible a datos no linealmente separables.

### ğŸ”¹ RegresiÃ³n LogÃ­stica
- Modelo estadÃ­stico para clasificaciÃ³n binaria y multiclase.
- Ãštil en problemas con relaciones lineales entre variables.

### ğŸ”¹ MÃ¡quinas de Vectores de Soporte (SVM)
- ClasificaciÃ³n utilizando hiperplanos Ã³ptimos.
- Permite el uso de diferentes **kernels** para mejorar precisiÃ³n.

### ğŸ”¹ Ãrboles de DecisiÃ³n
- Estructura jerÃ¡rquica para toma de decisiones.
- FÃ¡cil interpretaciÃ³n y ajuste de hiperparÃ¡metros.

### ğŸ”¹ Bosques Aleatorios (Random Forest)
- Conjunto de Ã¡rboles de decisiÃ³n para mejorar la generalizaciÃ³n.
- Reduce el sobreajuste comparado con modelos individuales.

## ğŸ—ï¸ ImplementaciÃ³n TÃ©cnica

### ğŸ“Œ SelecciÃ³n de CaracterÃ­sticas
- Se analizan correlaciones entre atributos para reducir dimensionalidad.
- MÃ©todos explorados: **Coeficiente de Pearson**, **PCA**.

### ğŸ“Œ Ajuste de HiperparÃ¡metros
- OptimizaciÃ³n mediante **bÃºsqueda en cuadrÃ­cula (Grid Search)** y **validaciÃ³n cruzada**.
- ComparaciÃ³n de diferentes configuraciones para cada modelo.

### ğŸ“Œ EvaluaciÃ³n de Modelos
Se utilizan mÃ©tricas para medir el rendimiento:
- **PrecisiÃ³n (Accuracy)**.
- **Matriz de confusiÃ³n** para anÃ¡lisis detallado.
- **Curvas ROC y AUC** para modelos probabilÃ­sticos.

### ğŸ“Œ VisualizaciÃ³n de Resultados
- Se generan grÃ¡ficos con `matplotlib` y `seaborn`.
- Comparaciones entre modelos mediante diagramas de barras y curvas de rendimiento.
